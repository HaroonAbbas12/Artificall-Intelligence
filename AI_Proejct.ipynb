{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# ðŸ”¥ PASTE YOUR TOKEN INSIDE THE QUOTES BELOW\n",
        "token = \"KGAT_1046dbac362f5e84561e77d5e5a066f7\"\n",
        "\n",
        "kaggle_dict = {\n",
        "    \"username\": \"haroon7878\",\n",
        "    \"key\": token\n",
        "}\n",
        "\n",
        "with open(\"/content/kaggle.json\", \"w\") as f:\n",
        "    json.dump(kaggle_dict, f)\n",
        "\n",
        "print(\"âœ” kaggle.json file created!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EUtvg4LEnqA",
        "outputId": "870e8da8-d19e-4b35-c9bd-667182abe7df"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ” kaggle.json file created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"âœ” kaggle.json installed successfully!\")\n"
      ],
      "metadata": {
        "id": "tVn9xpaGFWqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n"
      ],
      "metadata": {
        "id": "duBG4UIYFaXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip chest-xray-pneumonia.zip\n"
      ],
      "metadata": {
        "id": "f8I6oUVYHWUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUK7R3OJI8J4",
        "outputId": "7451cd3d-5fb2-4856-b656-bff830106a29"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/chest_xray /content/drive/MyDrive/chest_xray_new\n"
      ],
      "metadata": {
        "id": "4w8U9wTFJP5a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('/content/drive/MyDrive')\n"
      ],
      "metadata": {
        "id": "us2-1SbcLWmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_size = 224\n",
        "batch_size = 32\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/chest_xray_new\"\n",
        "\n",
        "train_path = base_path + \"/train\"\n",
        "val_path   = base_path + \"/val\"\n",
        "test_path  = base_path + \"/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "val_datagen   = ImageDataGenerator(rescale=1.0/255)\n",
        "test_datagen  = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO6Xw9a4LrKD",
        "outputId": "39b5d3a8-d7a6-43ad-a6a4-42ca5c7cf2c3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILD THE MODEL\n"
      ],
      "metadata": {
        "id": "jbE2qUzdMDX-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load MobileNetV2 base model (pretrained on ImageNet)\n",
        "base_model = MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False   # Freeze layers to speed up training\n",
        "\n",
        "# Add custom layers on top\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)  # Binary classification\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "6cEEuo-HMGS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL TRAINING"
      ],
      "metadata": {
        "id": "PPknfc1yMbHF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=5\n",
        ")\n"
      ],
      "metadata": {
        "id": "YID5R6Q7MdTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EVALUATE ON TEST DATA\n"
      ],
      "metadata": {
        "id": "kEcwUZXGTU1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "print(\"Test Loss:\", test_loss)\n"
      ],
      "metadata": {
        "id": "ERr32gvmTZdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UPLOAD AN XRAY IMAGE AND TEST\n"
      ],
      "metadata": {
        "id": "NjVY0E1YUBZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fine tune the base model"
      ],
      "metadata": {
        "id": "Uopsy26uV4oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze last 30 layers of MobileNetV2\n",
        "for layer in base_model.layers[-30:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "history_fine = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=3\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d03xjnVPV61e",
        "outputId": "bf64ef3e-4910-46a6-c50e-82ee0923b6a5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m163/163\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 2s/step - accuracy: 0.9106 - loss: 0.2972 - val_accuracy: 0.8750 - val_loss: 0.2035\n",
            "Epoch 2/3\n",
            "\u001b[1m163/163\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 2s/step - accuracy: 0.9665 - loss: 0.0844 - val_accuracy: 0.8750 - val_loss: 0.1818\n",
            "Epoch 3/3\n",
            "\u001b[1m163/163\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 2s/step - accuracy: 0.9799 - loss: 0.0562 - val_accuracy: 0.8750 - val_loss: 0.1703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "improve validation set"
      ],
      "metadata": {
        "id": "rzB38hZjWCIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1/255.0,\n",
        "    validation_split=0.15   # 15% validation\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_gen = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "id": "6R8p9fVQWGX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_weight = {0: 1.0, 1: 0.7}\n"
      ],
      "metadata": {
        "id": "K2PjLXw7bAXI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=5,\n",
        "    class_weight=class_weight\n",
        ")\n"
      ],
      "metadata": {
        "id": "nEriIeaubE9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "graphs"
      ],
      "metadata": {
        "id": "CG3c_YDjjVhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# ðŸ“Œ 1. Accuracy Graph\n",
        "# -----------------------------\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(\"Model Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "# -----------------------------\n",
        "# ðŸ“Œ 2. Loss Graph\n",
        "# -----------------------------\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title(\"Model Loss Over Epochs\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# ðŸ“Œ 3. Classification Report\n",
        "# -----------------------------\n",
        "test_pred = model.predict(test_gen)\n",
        "test_pred_classes = (test_pred > 0.5).astype(\"int32\")\n",
        "\n",
        "print(\"\\nðŸ“Œ Classification Report:\")\n",
        "print(classification_report(test_gen.classes, test_pred_classes, target_names=[\"NORMAL\", \"PNEUMONIA\"]))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# ðŸ“Œ 4. Confusion Matrix\n",
        "# -----------------------------\n",
        "cm = confusion_matrix(test_gen.classes, test_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=[\"NORMAL\", \"PNEUMONIA\"],\n",
        "            yticklabels=[\"NORMAL\", \"PNEUMONIA\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# ðŸ“Œ 5. Final Summary\n",
        "# -----------------------------\n",
        "print(\"\\n==============================\")\n",
        "print(\"ðŸ“Œ FINAL MODEL SUMMARY\")\n",
        "print(\"==============================\")\n",
        "\n",
        "print(f\"Train Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "print(f\"Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "print(\"\\nModel fully trained, evaluated, and ready for project submission.\")\n"
      ],
      "metadata": {
        "id": "xkaFMXTjjW6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/pneumonia_model.h5')\n"
      ],
      "metadata": {
        "id": "StEas96skf5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/pneumonia_model.keras')\n"
      ],
      "metadata": {
        "id": "g9YvOFH7k071"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}